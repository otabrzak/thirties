---
title: "Thirties"
author: "Ota Brzák"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen=10) # Print 0.00513 instead of 5.13e-03.

```

# The rules of the game

For this game analysis, I will be using slightly modified rules of the dice game 30s. The rules go like this: player starts with 30 lives and the players take turns clockwise. At the start of a turn, a player gets 6 dice. The goal of a player's turn is to throw the highest sum of all dice, which can be 36 at best.

The turn goes like this: the player throws all dice and has to set aside at least 1 of them. After he sets some dice aside (1 or more), he throws the rest of them again and repeats the process (sets at least 1 ř aside, throws the rest again), until there are no dice to throw and all are set aside. Since each throw contains at least 1 less die than the previous, the player can throw as many as 6 times in a turn.

After the final throw, the dice are summed up. If the result is lower than 30 (this is a recurring number in this game, as the name suggests), difference from 30 is subtracted from the player's lives (if I throw a 27, I lose 3 lives). If the result is higher than 30, the surplus over 30 is subtracted from the lives of the player on the left (if I throw a 35, the player on my left loses 5 lives). The last player with any lives left wins.

The scoring is not too important in this analysis, let's just establish that we want to find a strategy, that gets us as much above 30 as possible (ideally as close to 36 as possible). Let's now try to find it!

# Simplest strategy

Ok, a simple strategy would be to keep all the higher numbers and rethrow all the lower numbers. To keep it simple, let's set aside all 5's and 6's and look at what we get.

```{r simple turn simulation, echo=FALSE}
# This function simulates a player's turn
turn <- function() {
    
    # Number of dice still in game
    dice_left = 6
    
    # The number of current throw
    throw_num = 0
    
    # Final result of the turn
    final = c()
    
    while (dice_left>0){
        
        # Enumerate the throw
        throw_num = throw_num + 1
        
        # In a "bad" throw we do not want to keep any dice
        bad = TRUE
        throw = sample.int(6,size = dice_left, replace = TRUE)
        
        # Choose which dice to keep
        for (die in throw){
            
            if (die>=5){
                final = append(final, die)
                dice_left = dice_left - 1
                bad = FALSE
            }
        }
        
        # We are forced to keep 1 die, so we keep the highest value
        if (bad) {
            final = append(final, max(throw))
            dice_left = dice_left - 1
        }
    }
    
    final_sum = sum(final)
    return(final_sum)
}
```

```{r showcase simple turn simulation, echo=FALSE}
turn()
```

Now let's think about this for a minute. Imagine I throw a 5 in a last throw (only 1 die remaining). The expected value for the throw of 1 die is 3,5 and we scored much higher! Great.

But now, what if I throw a 5 in my first throw (with all 6 dice). Is it a good result, or is it not? As we can see, it now gets a bit more complicated. After this first throw, I will have the opportunity to see 15 more dice thrown (5 + 4 + 3 + 2 +1) and there is a pretty good chance we will see a 6 come up (to be exact it is $1-\left(\frac{5}{6}\right)^{15}=0.935$).

This changes our strategy a lot. Theoretically, for each throw ranging from 1 die to 6 dice there is a threshold that tells us whether to keep that die or not. That threshold is different for every throw, starts high and gradually lowers. But just where might this threshhold lie?

# Order statistics

This threshold is called the expected value. Expected value is the weighted average of all possible outcomes and shows us the average result of a throw or even a whole turn. We should start keeping numbers above expected value and try again with numbers below the expected value,

In the previous strategy, we only decided to keep 6s and 5s. Could we improve our strategy by computing the expected value of the next throw based on number we throw with? Let's try to estimate the maximum value thrown by $n$ dice, since we only need to keep 1 die (logically, we want to keep the highest value from a throw).

If we denote the $k$th order statistic ($k$th lowest element in the sample) as $X_{(k)}$, the probability that the element will equal some value $x$ is computed as

$$
{\displaystyle {\begin{aligned}P(X_{(k)}=x)&=\sum _{j=0}^{n-k}{n \choose j}\left((1-F(x))^{j}(F(x))^{n-j}-(1-F(x)+f(x))^{j}(F(x)-f(x))^{n-j}\right).\end{aligned}}}
$$

However, since we are looking for a maximum ($k=n$), we can simplify this formula. Let's denote three following values: $$\mathbf{p_{1}}=P(X<x)=F(x)-f(x), \mathbf{p_{2}}=P(X=x)=f(x),{\text{ and }}\mathbf{p_{3}}=P(X\>x)=1-F(x).$$

Using these, we can transform the formula and simplify:

$$
{\displaystyle {\begin{aligned}P(X_{(k)}=x)&=\sum _{j=0}^{n-k}{n \choose j}\left((1-F(x))^{j}(F(x))^{n-j}-(1-F(x)+f(x))^{j}(F(x)-f(x))^{n-j}\right),\\&=\sum _{j=0}^{n-k}{n \choose j}\left(p_{3}^{j}(p_{1}+p_{2})^{n-j}-(p_{2}+p_{3})^{j}(p_{1})^{n-j}\right),\\&=\sum_{j=0}^{n-n}{n\choose 0} \left( p_3^0(p_1+p_2)^n- (p_2 + p_3)^0(p_1)^n\right),
\\&=(p_1+p_2)^n-p_1^n,
\\&=F(x)^n-\left(F(x)-f(x)\right)^n
\\\end{aligned}}}
$$

\
To build a better strategy, we first need a theoretical baseline. We can use the order statistics to calculate the expected maximum value for a roll of *n* dice. This helps us understand what a "good" roll looks like.

```{r function for expected maxima, echo=FALSE}
e_max <- function(n){
    e = 0
    for (x in 1:6) {
        Fx=x/6
        fx=1/6
        e = e + x*(Fx**n - (Fx-fx)**n)
    }
    return(e)
}
```

The `e_max()` function will give us the expected maximum value from throwing *n* dice. In 30s, the expected value of the *n*th order statistic (the maximum) look like this:

```{r calculating the expected maxima}
n_range <- 6:1
expected_maxima <- round(e_max(n_range), digits = 2)
data.frame(n = n_range, expected_maximum = expected_maxima)
```

# Turn simulation

For further simulation and examination of solutions, we will code a function that simulates a turn based on our strategy (a vector of 6 thresholds).

```{r more complex turn simulation, echo=FALSE}
turn <- function(thresholds) {
    
    # We will compute expected maximal values for rolls with 1 to 6 dice
    thresholds <- thresholds

    
    dice_in_game <- 6
    final_hand <- c()
  
    # While we are still left with dice to throw, we will play
    while (dice_in_game > 0) {
    
        throw <- sample.int(n = 6, size = dice_in_game, replace = TRUE)
        initial_throw_size <- length(throw)
        improvement_found <- TRUE
        
        # Now let's choose the dice to keep going from highest value down
        while (improvement_found) {
          
            # Start with no expected improvement
            improvement_found <- FALSE 
          
            if (length(throw) == 0) {
                break
            }
          
            # With more dice left in game, the threshold for keeping is higher
            current_threshold <- thresholds[7-length(throw)]
            indices_to_keep <- which(throw >= current_threshold)
          
            # If we want actually want to keep any, we have found an improvement
            if (length(indices_to_keep) > 0) {
                improvement_found <- TRUE 
                final_hand <- append(final_hand, throw[indices_to_keep])
                throw <- throw[-indices_to_keep]
            }
        }
        
        # If we haven't found any sufficient values, we will bite the bullet and
        # keep the highest value
        if (length(throw) == initial_throw_size) {
            max_index <- which.max(throw)
            final_hand <- append(final_hand, throw[max_index])
            throw <- throw[-max_index]
        }
        
        dice_in_game <- length(throw)
    }
  
    return(sum(final_hand))
}
```

# Brute force solution

If we think the actual space of possible solutions, in this case, it is not really that large. There are a few rules that cut down on the number of solutions greatly:

1.  Each vector has exactly 6 elements, with each element being 1 of 6 possible values.

2.  Even with 1 die, we expect to roll 3.5 on average. That means that with 1 or more dice still in play (this is true constantly), we should not settle with anything less than a 4. This cuts the number of possible solutions in half (we only settle for 4s, 5s, or 6s).

3.  Our expected value from a single throw goes down with the amount of dice in that throw. By this idea we can ignore all threshold vectors, in which any value in position i is greater than the value in position i-1.

Implementing all of these ideas, we are left with 28 vectors for which these rules are true.

```{r creting solution vector space, echo=FALSE}
all_vectors <- expand.grid(rep(list(6:4), 6))

valid_vectors <- all_vectors[apply(all_vectors, 1, function(x) all(diff(x) <= 0)), ]


valid_vectors <- cbind(valid_vectors, rep(0,nrow(valid_vectors)))
names(valid_vectors) <- c(paste0("T", 1:6),"score")
row.names(valid_vectors) <- NULL
print(valid_vectors)
```

Now we simulate 10000 turns for each strategy vector and compute the average score.

```{r evaluating all valid vectors,include=FALSE}
n_vectors = nrow(valid_vectors)

for (i in 1:n_vectors) {
    
    current_vector <- as.double(valid_vectors[i,1:6])
    
    sim_results <- replicate(10000, {
        sum(turn(current_vector))
    })
    
    valid_vectors[i,"score"]=mean(sim_results)
    
    cat("iteration", i,"out of",n_vectors, "\n")
}
```

```{r showing valid vector scores}
print(valid_vectors)

```

```{r plotting valid vector scores, echo=FALSE}
library(ggplot2)

# Make sure 'score' is numeric
valid_vectors$score <- as.numeric(valid_vectors$score)

# Create a string for the threshold labels
valid_vectors$threshold_label <- apply(valid_vectors[,1:6], 1, function(x) {
  paste(x, collapse = ",")
})

# Get the top 10 vectors
top_10_vectors <- head(valid_vectors[order(valid_vectors$score, decreasing = TRUE), ], 10)

# Create the plot
p1 <- ggplot(top_10_vectors, aes(x = reorder(threshold_label, score), y = score)) +
  geom_bar(stat = "identity", fill = "#0073C2") +
  geom_text(aes(label = round(score, 2)), hjust = 1.2, color = "white", fontface = "bold") +
  
  # coord_flip() flips the x and y axes.
  # So, to zoom the horizontal axis (which was 'y'), we set 'ylim'.
  coord_flip(ylim = c(29.8, 30.2)) + 
  
  labs(
    title = "Top 10 Strategies from Brute-Force Simulation",
    subtitle = "Average score from 10,000 turns per strategy",
    x = "Threshold Vector (Dice: 6, 5, 4, 3, 2, 1)",
    y = "Average Score"
  ) +
  theme_light()

ggsave("bruteforce_results_plot.png", plot = p1, width = 8, height = 5)
```

Since the scores still might be inaccurate, Let's pick top 3 solutions and simulate 1000000 turns for each one.

```{r more accurate scoring, echo=FALSE}
sorted_vectors <- valid_vectors[order(valid_vectors$score, decreasing = TRUE), ]
best_vectors <- head(sorted_vectors, 3)

score <- 0

n_vectors <- nrow(best_vectors)

for (i in 1:n_vectors) {
    
    current_vector <- as.double(best_vectors[i,1:6])
    
    sim_results <- replicate(1000, {
        sum(turn(current_vector))
    })
    
    last_score <- score
    score <- mean(sim_results)
    
    best_vectors[i,"score"] <- score
    
    cat("iteration", i,"out of",n_vectors, "\n")
    
    if (score>last_score) {
        best_sim_results <- sim_results
    }
}
print(best_vectors)
```

Ok, looks like we have our solution!!! There are 2 vectors performing nearly identically with only very slight differences in scoring: $[6,6,6,5,5,4]$ and $[6,6,6,6,5,4]$.

# Genetic algorithm
We have already found the top solution through brute force. However, with higher number of options the time to find the optimal solution would grow exponentially (the brute force algorithm has complexity of $\mathcal{O}(2^n)$, which is absolutely horrible). Could there be another way of finding a solution?

Brute force worked here because the constrained search space (28 vectors) was small. For more complex scenarios (e.g., allowing lower thresholds), this approach becomes computationally overwhelming. Since this game has a very large ammount of outcomes, it would be super tedious to solve analytically. The way to go here is to look into a more efficient optimization algorithm. 

In this case, we do not have any continuous function to optimize. Therefore, I implemented a genetic algorithm as a more scalable optimization method and to verify the brute-force result.


```{r make_population, echo=FALSE}
make_population <- function(n) {
    
    population <- replicate(n,sample(1:6, 6, replace = TRUE))
    
    
    population <- as.data.frame(t(population))
    
    col_names <- (c("T1","T2","T3","T4","T5","T6"))
    colnames(population) <- col_names
    population$score <- replicate(n,0)
    
    return(population)
}
```

```{r evaluate_population, echo=FALSE}
evaluate_population <- function(population,epoch, n_epochs, sampled_turns){
    
    n_chrom <- nrow(population)
    
    cat(paste("\n--- Evaluating Epoch:", epoch, "---\n"))
    
    pb <- txtProgressBar(min = 0, max=n_chrom, style = 3)
    
    for (chrom_i in 1:n_chrom) {
    
        chromosome <- as.double(population[chrom_i,1:6])
        
        
        repetitions <- ceiling(100 + (sampled_turns-100)*(epoch/n_epochs)^3)
        sim_results <- replicate(repetitions,sum(turn(chromosome)))
        
        sim_score <- mean(sim_results)
        population$score[chrom_i] <- sim_score
        
        setTxtProgressBar(pb, chrom_i)        
    }
    close(pb)
    cat("\n")
    return(population)
}


```

```{r crossover, echo=FALSE}
crossover <- function(chromosome_x, chromosome_y, crossover_point ,prob_mutate){
    
    child <- c(chromosome_x[1:crossover_point], 
               chromosome_y[(crossover_point + 1):6])
    
    if(runif(1)<=prob_mutate){
        
        mutation_index <- sample(1:6,1)
        mutated_value <- child[mutation_index]
        
        if (mutated_value==1) {
            child[mutation_index] <- 2
        }
        
        else if (mutated_value==6) {
            child[mutation_index] <- 5
        }
        else {
            
            if (runif(1)>0.5){
                child[mutation_index] <- mutated_value -1
            }
            else{
                                   child[mutation_index] <- mutated_value + 1 
            }
        }
    }
    return(child)
}

chx = c(1,1,1,1,1,1)
chy = c(6,6,6,6,6,6)
print(crossover(chx,chy,crossover_point = 3,prob_mutate = 0.1))
```

```{r reproduce_population, echo=FALSE}
reproduce_population <- function(population){
    
    new_population <- list()
    n <- nrow(population)
    for (i in 1:n) {
        
        contestants_index <- sample(1:n, 4,replace = TRUE)
        contestants <- population[contestants_index,]
        
        if (contestants$score[1]>contestants$score[2]) {
            chromosome_x <- as.numeric(contestants[1,1:6])
        }
        else {
            chromosome_x <- as.numeric(contestants[2,1:6])
        }
        
        if (contestants$score[3]>contestants$score[4]) {
            chromosome_y <- as.numeric(contestants[3,1:6])
        }
        else {
            chromosome_y <- as.numeric(contestants[4,1:6]) 
        }
        child <- crossover(chromosome_x = chromosome_x,
                           chromosome_y = chromosome_y,
                           crossover_point = 3,
                           prob_mutate = 0.1)
        child <- c(child,0)
        new_population[[i]] <- child
    }
    new_population <- as.data.frame(do.call(rbind,new_population))
    colnames(new_population) <- colnames(population)
    return(new_population)
}
```

```{r create_evolution_plot, echo=FALSE}
create_evolution_plot <- function(evolution_progress){
  library(ggplot2)
  p <- ggplot(evolution_progress, aes(x = epoch, y = epoch_avg_score)) +
      
      # Add a blue line, make it slightly thicker
      geom_line(color = "#0072B2", size = 1) + 
      
      # Add points for each epoch to show the discrete steps
      geom_point(color = "#0072B2", size = 2) + 
      
      # Make sure the x-axis only shows integer epoch numbers
      scale_x_continuous(breaks = 1:length(evolution_progress$epoch)) +
      
      # Add better titles and labels
      labs(
        title = "Genetic Algorithm Evolution Progress",
        subtitle = "Average population score per epoch",
        x = "Epoch",
        y = "Average Score"
      ) +
      
      # theme_minimal() is great, theme_light() is also a clean option
      theme_light() 
      return(p)
}
```

```{r evolve, echo=FALSE, results = "hide"}

evolve <- function(n, n_epochs, sampled_turns, early_stop=5){
    
    best_chromosome <- c(0,0,0,0,0,0,0)
    last_best_chromosome <- c(0,0,0,0,0,0,0)
    i_early_stop <- 0

    evolution_progress <- list()
    
    for (epoch in 1:n_epochs){
        
        if (epoch==1){
            population <- make_population(n)
        }
        else {
            population <- reproduce_population(population = population)
        }
        
        population <- evaluate_population(population = population,
                                          epoch = epoch,
                                          n_epochs = n_epochs,
                                          sampled_turns = sampled_turns)
        
        last_best_chromosome <- best_chromosome
        best_chromosome <- as.numeric(population[which.max(population$score),])
        cat("--- Best Chromosome:",
            best_chromosome,
            " ---","\n","\n","\n")
        if(identical(last_best_chromosome[1:6],best_chromosome[1:6])){
            i_early_stop <- i_early_stop +1
        }
        else {
            i_early_stop <- 0
        }
        
        evolution_progress[[epoch]] <- c(epoch,mean(population$score))
        
        if (i_early_stop>=early_stop) {
            cat("Stopping early, solution did not change for",i_early_stop,"epochs.","\n")
            break
        }
    }
    
    evolution_progress <- as.data.frame(do.call(rbind,evolution_progress))
    colnames(evolution_progress) <- c("epoch","epoch_avg_score")
    p2 <- create_evolution_plot(evolution_progress = evolution_progress)
    return(list("population"=population, "p2"=p2))
}

evolution <- evolve(n = 100,
             n_epochs = 20,
             sampled_turns = 1000,
             early_stop = 5)

```

```{r plotting the evolution}
p2 <- evolution$p2
evolved_population <- evolution$population
print(p2)
ggsave("evolution_results_plot.png", plot = p2, width = 8, height = 5)
```

# Conclusions

Both the brute force simulation (after 1 million runs per top strategy) and the genetic algorithm converged on the optimal strategy: $[6, 6, 6, 5, 5, 4]$, yielding an average score of approximately 30.10. This convergence validates both methods. The brute force search with a very high number of simulations always converges, however, the genetic algorithm uses a much lower number of simulations for scoring to for approximate scoring and speeding up the process. Because of that, the optimum found by the genetic algorithm may vary slightly and both algorithms will likely return different scores due to the difference of simulation length.

## Comparing the solutions

We print out both of our best solutions and compare them.

```{r algorithm comparison}
cat("Brute force result:","\n",as.numeric((best_vectors[which.max(best_vectors$score),1:7])))
cat("\n","\n")
cat("GA result:","\n",as.numeric(evolved_population[which.max(evolved_population$score),]))
```

Since the brute force result was scored by a much higher number of turns, it will be much more precise than the GA solution. We can even calculate the 95% confidence interval for the true expected score using this strategy, since we have a log of 1000000 simulations for the top strategy. From these, we can calculate the standard deviation, the z-scores and the bounds of the CI.

```{r confidence intervals, echo=FALSE}
# 1. Get the basic statistics from your results
x_bar <- mean(best_sim_results)   # Sample Mean
s <- sd(best_sim_results)         # Sample Standard Deviation
n <- length(best_sim_results)     # Sample Size

# 2. Calculate the Standard Error (SE)
# This is the standard deviation of the *sample mean*
se <- s / sqrt(n)

# 3. Get the Critical Value (z-score)
# For a 95% CI, this value is always 1.96
# (You can get it with qnorm(0.975))
z_critical <- 1.96

# 4. Calculate the Margin of Error
margin_of_error <- z_critical * se

# 5. Build the Confidence Interval
lower_bound <- x_bar - margin_of_error
upper_bound <- x_bar + margin_of_error

# Print the results
cat(paste("95% CI: [", round(lower_bound, 3), ",", round(upper_bound, 3), "]\n"))

```
